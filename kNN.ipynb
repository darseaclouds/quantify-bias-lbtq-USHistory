{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4169b5a",
   "metadata": {},
   "source": [
    "# kNN\n",
    "Euclidean distance and cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c19d2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import json\n",
    "import sys\n",
    "MAX_INT = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e38c3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['broadcast', 'awful', 'gay', 'homosexual', 'lesbian', 'bisexual', 'queer', 'transgender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd85bd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(v1, v2):\n",
    "    if v1 == 0 or v2 == 0:\n",
    "        return MAX_INT\n",
    "    \n",
    "    n1 = np.array(v1)\n",
    "    n2 = np.array(v2)\n",
    "    \n",
    "    return (sum(np.square(n1-n2))) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0911c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findNearestNeighbors(vec, dataframe, k):\n",
    "    distances = [(euclideanDistance(vec, list(row)), index) for index,row in dataframe.iterrows()]\n",
    "    return [v for k,v in sorted(distances)[:k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d617a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputNN(year, word, k, embed):\n",
    "    assert embed == 'lemmas' or embed == 'words'\n",
    "    \n",
    "    # load dataframe\n",
    "    with open('sgns-' + embed + '/'+str(year)+'-vocab.pkl', 'rb') as f:\n",
    "        vocab = pickle.load(f)\n",
    "        #print(np.shape(vocab))\n",
    "    filename = ('sgns-' + embed + '/'+str(year)+'-w.npy')\n",
    "    vecs = np.load(filename)\n",
    "    #print(np.shape(vecs))\n",
    "   \n",
    "    df = pd.DataFrame(vecs, index=vocab)\n",
    "    df = df[df[0] != 0] # drop all vectors that are too small to carry meaning\n",
    "    \n",
    "    if word not in df.index:\n",
    "        return[0]\n",
    "    \n",
    "    wordList = list(df.loc[word])\n",
    "    \n",
    "    #with open('coha-adj-' + embed +'.txt') as file:\n",
    "    with open('adjectives.txt') as file:\n",
    "        adjList = file.readlines()\n",
    "        \n",
    "    adjList = [a.strip() for a in adjList]\n",
    "    \n",
    "    #df = df[df.index.isin(adjList)] # collapse df to just include adjectives\n",
    "    \n",
    "    nn = findNearestNeighbors(wordList, df, k)  \n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e420e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['queer',\n",
       " 'solemn',\n",
       " 'lazy',\n",
       " 'charming',\n",
       " 'cheerful',\n",
       " 'jolly',\n",
       " 'timid',\n",
       " 'hasty',\n",
       " 'suspicious',\n",
       " 'foolish',\n",
       " 'discreet',\n",
       " 'frightening',\n",
       " 'stubborn',\n",
       " 'witty',\n",
       " 'idealistic',\n",
       " 'clever',\n",
       " 'awkward',\n",
       " 'dignified',\n",
       " 'impatient',\n",
       " 'neat',\n",
       " 'peculiar',\n",
       " 'gloomy',\n",
       " 'sentimental',\n",
       " 'sly',\n",
       " 'shrewd',\n",
       " 'gorgeous',\n",
       " 'shy',\n",
       " 'fearful',\n",
       " 'ignorant',\n",
       " 'courteous']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputNN(1970, \"queer\", 30, 'lemmas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f9e877ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word in keywords:\n",
    "    words[word] = {}\n",
    "    for i in range(1810, 2001, 10):\n",
    "        words[word][i] = outputNN(i, word, 30, 'lemmas') # top 30 nn\n",
    "    with open('nn-lemmas/adj/'+word+'.json', 'w') as outfile:\n",
    "        json.dump(words[word], outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "124caa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word in keywords:\n",
    "    words[word] = {}\n",
    "    for i in range(1810, 2001, 10):\n",
    "        words[word][i] = outputNN(i, word, 30, 'words') # top 30 nn\n",
    "    with open('nn-words/adj/'+word+'.json', 'w') as outfile:\n",
    "        json.dump(words[word], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54265572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change adj to all words\n",
    "\n",
    "words = {}\n",
    "\n",
    "for word in keywords:\n",
    "    words[word] = {}\n",
    "    for i in range(1810, 2001, 10):\n",
    "        words[word][i] = outputNN(i, word, 30, 'lemmas') # top 30 nn\n",
    "    with open('nn-lemmas/all/'+word+'.json', 'w') as outfile:\n",
    "        json.dump(words[word], outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b62de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}\n",
    "\n",
    "for word in keywords:\n",
    "    words[word] = {}\n",
    "    for i in range(1810, 2001, 10):\n",
    "        words[word][i] = outputNN(i, word, 30, 'words') # top 30 nn\n",
    "    with open('nn-words/all/'+word+'.json', 'w') as outfile:\n",
    "        json.dump(words[word], outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e623d445",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
